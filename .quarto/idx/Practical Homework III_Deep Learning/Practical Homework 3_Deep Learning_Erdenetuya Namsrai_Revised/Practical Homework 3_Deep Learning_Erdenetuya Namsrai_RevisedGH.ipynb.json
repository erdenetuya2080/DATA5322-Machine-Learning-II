{"title":"Practical Homework 3: Deep Learning","markdown":{"yaml":{"title":"Practical Homework 3: Deep Learning"},"headingText":"Erdenetuya Namsrai","containsRefs":false,"markdown":"\n\n\n\n\n\n\n# 1. Data Preparation\n\nA dataset of 12 bird species was created, with each species stored as a 3D array representing spectrograms of samples, frequencies, and time steps.\n\n# 2. Binary CNN Model with two bird species \"amecro and amerob\"\n\n# 2.1 Binary CNN Model_1 \"amecro and amerob\"\n\nResult:\nTrain Accuracy: 98.33%\nTest Accuracy: 84.72%\n\nThis CNN model learned the training data very well, achieving 98.33% accuracy. However, its test accuracy was lower at 84.72%, which suggests the model may be overfitting to the training data. \n\nResult:\nThese plots show strong learning on the training data, reaching near-perfect accuracy with very low training loss. However, the validation accuracy is noticeably lower and fluctuates across epochs, while validation loss remains steady. This suggests that the model may be overfitting—performing well on the training set but not generalizing as well to new data. \n\nResult: This confusion matrix shows that the model is very good at detecting amerob, with a recall of 100%, while it detects amecro with 45% recall, meaning many amecro cases are misclassified. However, the model still achieves a high overall accuracy of 85% and has balanced weighted performance metrics.\n\nNow we build a CNN binary model 2 to fix overfitting and improve the performance of the first model.\n\n# 2.2 Binary CNN Model_2\n\nResult: \nThe CNN binary model achieved a training accuracy of 93.75% and a good test accuracy of 82%, indicating effective learning and good generalization. Although there is a small overfitting gap, the use of dropout and the Adam optimizer helped maintain solid test performance.\n\nResult:\nThe model shows strong learning behavior, achieving nearly 93% accuracy on the training set and stabilizing around 82% on the validation set. The sharp drop and stabilization of both training and validation losses indicate that the model converged effectively. However, the consistent performance gap points to mild overfitting.\n\nResult:\nThis CNN model achieved a test accuracy of 82% and performed in identifying the class amerob, with a recall of 88% and an F1-score of 88%. While performance on the class amecro improved, the model still showed weaker generalization to this class, with a recall of 65% and an F1-score of 67%. Despite using balanced data and class weighting, this performance gap suggests that amecro may exhibit more complex or less distinctive patterns in its spectrograms, requiring further refinement or targeted augmentation to improve model sensitivity.\n\n# 2.3 Tuned Binary CNN Model_3 \n\nResult: \nThis tuned CNN binary model achieved a training accuracy of 91% and a test accuracy of 85%, demonstrating that the model has effectively learned from the training data and generalizes reasonably well to unseen data. The relatively small gap between training and test accuracy suggests that overfitting is under control and the model maintains good generalization performance.\n\nResult: The tuned binary CNN model, enhanced with regularization, balanced training, and early stopping, achieved strong training performance and improved validation accuracy. \n\nResult: The tuned binary CNN model achieved an overall accuracy of 85% and demonstrated balanced precision across both classes. It performed strongly in identifying the majority class amerob, with a recall of 96% and an F1-score of 90%. However, the model struggled to detect the minority class amecro, with a lower recall of 55% and F1-score of 67%. \n\n# 3. Multi-class CNN Model\n\n# 3.1 Multi-class CNN Model_1 with all 12 bird species\n\nResult: The model only reached 99.34% accuracy on training data and 69.14% on test data, which is just slightly better than random guessing for 12 classes. This means the model did not learn well and likely needs better training data, a stronger model, or improved input features to perform better.\n\nResult: The plots demonstrate strong performance on the training data but unstable and fluctuating results on the validation set, indicating overfitting and limited generalization to unseen data.\n\nResult: The multi-class CNN model achieved an overall accuracy of 69% across 12 bird species. These birds can be detected by the model, as indicated by amecro, amerob, bkcchi, houfin, norfli, rewbla, and spotow.\n\n\n\n# 3.2 Multi-class CNN Model_2\n\nResult: The second Multi-class CNN model reached 95.4% accuracy on training data and 72% on test data. The test accuracy reveals a performance drop on unseen data, which suggests overfitting. While the model generalizes moderately well than the previous model.\n\nResult: Although this plot shows very high training accuracy, validation accuracy improves slowly and fluctuates, resulting in high validation loss. This indicates overfitting. The model learns well from the training data but struggles to generalize to unseen data.\n\nResult: The second multi-class CNN model achieved an overall accuracy of 72% across 12 bird species. These birds can be detected by models, as indicated by amerob, bkcchi, and daejun.     \n\n# 3.3 Tuned Multi-class CNN Model \n\nResult: The tuned Multi-class CNN model reached 93% accuracy on training data and 73% on test data. This indicates strong learning during training but some degree of overfitting. However, the test accuracy of 73% aligns with the multi-class classification report, showing consistent generalization on unseen data.\n\nResult: The tuned multi-class CNN model demonstrates strong learning ability and good generalization. Although validation accuracy is slightly less than training, the steady upward trend and steady loss indicate a well-trained and reliable CNN for identifying multiple bird species.\n\nResult: The Tuned multi-class CNN model achieved an overall accuracy of 73% across 12 bird species. The model performed best on species such as daejun and amecro are showing both high precision, F1-score, and recall. Conversely, species like bewwre and houfin were more difficult to classify.\n\n# 4.External Test Data\n","srcMarkdownNoYaml":"\n\n\n\n## Erdenetuya Namsrai\n\n\n\n# 1. Data Preparation\n\nA dataset of 12 bird species was created, with each species stored as a 3D array representing spectrograms of samples, frequencies, and time steps.\n\n# 2. Binary CNN Model with two bird species \"amecro and amerob\"\n\n# 2.1 Binary CNN Model_1 \"amecro and amerob\"\n\nResult:\nTrain Accuracy: 98.33%\nTest Accuracy: 84.72%\n\nThis CNN model learned the training data very well, achieving 98.33% accuracy. However, its test accuracy was lower at 84.72%, which suggests the model may be overfitting to the training data. \n\nResult:\nThese plots show strong learning on the training data, reaching near-perfect accuracy with very low training loss. However, the validation accuracy is noticeably lower and fluctuates across epochs, while validation loss remains steady. This suggests that the model may be overfitting—performing well on the training set but not generalizing as well to new data. \n\nResult: This confusion matrix shows that the model is very good at detecting amerob, with a recall of 100%, while it detects amecro with 45% recall, meaning many amecro cases are misclassified. However, the model still achieves a high overall accuracy of 85% and has balanced weighted performance metrics.\n\nNow we build a CNN binary model 2 to fix overfitting and improve the performance of the first model.\n\n# 2.2 Binary CNN Model_2\n\nResult: \nThe CNN binary model achieved a training accuracy of 93.75% and a good test accuracy of 82%, indicating effective learning and good generalization. Although there is a small overfitting gap, the use of dropout and the Adam optimizer helped maintain solid test performance.\n\nResult:\nThe model shows strong learning behavior, achieving nearly 93% accuracy on the training set and stabilizing around 82% on the validation set. The sharp drop and stabilization of both training and validation losses indicate that the model converged effectively. However, the consistent performance gap points to mild overfitting.\n\nResult:\nThis CNN model achieved a test accuracy of 82% and performed in identifying the class amerob, with a recall of 88% and an F1-score of 88%. While performance on the class amecro improved, the model still showed weaker generalization to this class, with a recall of 65% and an F1-score of 67%. Despite using balanced data and class weighting, this performance gap suggests that amecro may exhibit more complex or less distinctive patterns in its spectrograms, requiring further refinement or targeted augmentation to improve model sensitivity.\n\n# 2.3 Tuned Binary CNN Model_3 \n\nResult: \nThis tuned CNN binary model achieved a training accuracy of 91% and a test accuracy of 85%, demonstrating that the model has effectively learned from the training data and generalizes reasonably well to unseen data. The relatively small gap between training and test accuracy suggests that overfitting is under control and the model maintains good generalization performance.\n\nResult: The tuned binary CNN model, enhanced with regularization, balanced training, and early stopping, achieved strong training performance and improved validation accuracy. \n\nResult: The tuned binary CNN model achieved an overall accuracy of 85% and demonstrated balanced precision across both classes. It performed strongly in identifying the majority class amerob, with a recall of 96% and an F1-score of 90%. However, the model struggled to detect the minority class amecro, with a lower recall of 55% and F1-score of 67%. \n\n# 3. Multi-class CNN Model\n\n# 3.1 Multi-class CNN Model_1 with all 12 bird species\n\nResult: The model only reached 99.34% accuracy on training data and 69.14% on test data, which is just slightly better than random guessing for 12 classes. This means the model did not learn well and likely needs better training data, a stronger model, or improved input features to perform better.\n\nResult: The plots demonstrate strong performance on the training data but unstable and fluctuating results on the validation set, indicating overfitting and limited generalization to unseen data.\n\nResult: The multi-class CNN model achieved an overall accuracy of 69% across 12 bird species. These birds can be detected by the model, as indicated by amecro, amerob, bkcchi, houfin, norfli, rewbla, and spotow.\n\n\n\n# 3.2 Multi-class CNN Model_2\n\nResult: The second Multi-class CNN model reached 95.4% accuracy on training data and 72% on test data. The test accuracy reveals a performance drop on unseen data, which suggests overfitting. While the model generalizes moderately well than the previous model.\n\nResult: Although this plot shows very high training accuracy, validation accuracy improves slowly and fluctuates, resulting in high validation loss. This indicates overfitting. The model learns well from the training data but struggles to generalize to unseen data.\n\nResult: The second multi-class CNN model achieved an overall accuracy of 72% across 12 bird species. These birds can be detected by models, as indicated by amerob, bkcchi, and daejun.     \n\n# 3.3 Tuned Multi-class CNN Model \n\nResult: The tuned Multi-class CNN model reached 93% accuracy on training data and 73% on test data. This indicates strong learning during training but some degree of overfitting. However, the test accuracy of 73% aligns with the multi-class classification report, showing consistent generalization on unseen data.\n\nResult: The tuned multi-class CNN model demonstrates strong learning ability and good generalization. Although validation accuracy is slightly less than training, the steady upward trend and steady loss indicate a well-trained and reliable CNN for identifying multiple bird species.\n\nResult: The Tuned multi-class CNN model achieved an overall accuracy of 73% across 12 bird species. The model performed best on species such as daejun and amecro are showing both high precision, F1-score, and recall. Conversely, species like bewwre and houfin were more difficult to classify.\n\n# 4.External Test Data\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"output-file":"Practical Homework 3_Deep Learning_Erdenetuya Namsrai_RevisedGH.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.31","output-dir":"../../docs","theme":["cosmo","brand"],"title":"Practical Homework 3: Deep Learning"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}