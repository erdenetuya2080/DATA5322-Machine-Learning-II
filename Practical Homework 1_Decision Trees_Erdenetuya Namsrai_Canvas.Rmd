---
title: "Practical Homework 1 Decision Trees"
author: "Erdenetuya Namsrai"
date: "2025-04-06"
output: html_document
---



## 1. Youth dataset

```{r}
url <- "https://raw.githubusercontent.com/mendible/5322/main/Homework%201/youth_data.Rdata"
download.file(url, destfile = "youth_data.Rdata", mode = "wb")

loaded_dataset <- load("youth_data.Rdata")
youth_data_df <- get(loaded_dataset[1])

cleaned_youth_data <- na.omit(youth_data_df)
youth <- cleaned_youth_data
#youth
```


## 2.1 Binary classification (e.g. has or has not used cigarettes) -->Tree with MRJFLAG --> marijuana ever used (0 = never, 1 = ever)

```{r}
library(tree)
library(tidyverse)

youth_binary <- cleaned_youth_data[, c(demographic_cols, youth_experience_cols, "MRJFLAG")]
youth_binary$MRJFLAG <- as.factor(youth_binary$MRJFLAG)

set.seed(123)

training_set <- sample(1:nrow(youth_binary), 0.7 * nrow(youth_binary))
training_data <- youth_binary[training_set, ]
testing_data <- youth_binary[-training_set, ]

tree_youth <- tree(MRJFLAG ~ ., data = training_data)
summary(tree_youth)
```


```{r}
tree_youth
```


```{r}
plot(tree_youth)
text(tree_youth, pretty = 0)
```


```{r}
testing_data <- as.data.frame(testing_data)
test_pred <- predict(tree_youth, testing_data, type = "class")

confusion_matrix_dt <- table(Predicted = test_pred, Actual = testing_data$MRJFLAG)
confusion_matrix_dt

accuracy_dt <- mean(test_pred == testing_data$MRJFLAG)
#(198+1941)/(198+1941+121+215)
test_error_rate_dt <- 1 - accuracy_dt
#(121+215)/2475

cat('Accuracy:', mean(test_pred == testing_data$MRJFLAG), "\n")
cat('Test Error Rate:', round(test_error_rate_dt, 4), "\n")
```


```{r}
set.seed(7)

cv.youth <- cv.tree(tree_youth, FUN = prune.misclass)
names(cv.youth)
cv.youth
```


```{r}
plot(cv.youth$size, cv.youth$dev, type = "b",
     xlab = "Tree Size (Number of Terminal Nodes)",
     ylab = "CV Classification Error Rate",
     main = "CV Error vs. Tree Size",
     pch = 19, col = "blue")
```


```{r}
optimal_size_CV <- cv.youth$size[which.min(cv.youth$dev)]
optimal_size_CV
```


```{r}
pruned_tree <- prune.misclass(tree_youth, best = 5)
pruned_tree

plot(pruned_tree, main = "Pruned tree")
text(pruned_tree, pretty = 0)
```


```{r}
testing_data <- as.data.frame(testing_data)
prune_pred_youth <- predict(pruned_tree, testing_data, type = "class")

confusion_matrix_pru <- table(Predicted = prune_pred_youth, Actual = testing_data$MRJFLAG)
confusion_matrix_pru

accuracy_pru <- mean(prune_pred_youth == testing_data$MRJFLAG)
#(198+1941)/(198+1941+121+215)
test_error_rate_pru <- 1 - accuracy_pru
#(121+215)/2475

cat('Accuracy:', mean(prune_pred_youth == testing_data$MRJFLAG), "\n")
cat('Test Error Rate:', round(test_error_rate_pru, 4), "\n")
```


## 2.2 Binary Classification --> Bagging --> with MRJFLAG --> marijuana ever used (0 = never, 1 = ever)

```{r}
library(randomForest)

training_data_clean <- na.omit(training_data) 
bag_youth = randomForest(MRJFLAG ~ ., data = training_data_clean, mtry = floor(sqrt(ncol(training_data_clean))), importance = TRUE)
bag_youth
```


```{r}
pred_bag_youth = predict(bag_youth, newdata = testing_data, type = 'class')

confusion_matrix_bag <- table(Predicted = pred_bag_youth, Actual = testing_data$MRJFLAG)
confusion_matrix_bag

accuracy_bag <- mean(pred_bag_youth == testing_data$MRJFLAG)
#(180+1988)/(180+1988+74+233)
test_error_rate_bag <- 1 - accuracy_bag
#(74+233)/2475

cat('Accuracy:', mean(pred_bag_youth == testing_data$MRJFLAG), "\n")
cat('Test Error Rate:', round(test_error_rate_bag, 4), "\n")
```


```{r}
top_10_bag_MRJFLAG = head(importance(bag_youth),10) 
top_10_bag_MRJFLAG
```


```{r}
varImpPlot(bag_youth, n.var = 10, sort = TRUE, main = 'The Most Important 10 Variables_MRJFLAG_Bagging')
```


## 2.3 Binary Classification --> Random Forest -->  with MRJFLAG --> marijuana ever used (0 = never, 1 = ever)

```{r}
set.seed(1)
rf_youth = randomForest(MRJFLAG ~ ., data = training_data_clean, mtry = sqrt(ncol(training_data_clean)), importance = TRUE)
rf_youth
```


```{r}
yhat.rf <- predict(rf_youth, newdata = testing_data, type = 'class')

confusion_matrix_rf <- table(Predicted = yhat.rf, Actual = testing_data$MRJFLAG)
confusion_matrix_rf

accuracy_rf <- mean(yhat.rf == testing_data$MRJFLAG, na.rm = TRUE)
test_error_rf <- 1 - accuracy_rf

cat("Accuracy:", round(accuracy_rf, 4), "\n")
cat("Test Error Rate:", round(test_error_rf, 4), "\n")
```


```{r}
top_10_rf_MRJFLAG = head(importance(rf_youth),10)
top_10_rf_MRJFLAG
```


```{r}
varImpPlot(rf_youth, n.var = 10, sort = TRUE, main = 'The Most Important 10 Variables_MRJFLAG Random Forest ')
```


## 3.1 Binary classification (e.g. has or has not used cigarettes) Tree with TOBFLAG --> any tobacco ever used (0 = never, 1 = ever)

```{r}
youth_binary <- cleaned_youth_data[, c(demographic_cols, youth_experience_cols, "TOBFLAG")]
youth_binary$TOBFLAG <- as.factor(youth_binary$TOBFLAG)

set.seed(123)

training_set <- sample(1:nrow(youth_binary), 0.7 * nrow(youth_binary))
training_data <- youth_binary[training_set, ]
testing_data <- youth_binary[-training_set, ]

tree_youth2 <- tree(TOBFLAG ~ ., data = training_data)
summary(tree_youth2)
```


```{r}
tree_youth2
```


```{r}
plot(tree_youth2)
text(tree_youth2, pretty = 0)
```


```{r}
testing_data <- as.data.frame(testing_data)
test_pred <- predict(tree_youth2, testing_data, type = "class")

confusion_matrix_tobflag <- table(Predicted = test_pred, Actual = testing_data$TOBFLAG)
confusion_matrix_tobflag

accuracy_tobflag <- mean(test_pred == testing_data$TOBFLAG)
#(2224+14)/(2224+299+8+14)
test_error_rate_tobflag <- 1 - accuracy_tobflag
#(8+229)/2475

cat('Accuracy:', mean(test_pred == testing_data$TOBFLAG), "\n")
cat('Test Error Rate:', round(test_error_rate_tobflag, 4), "\n")
```


```{r}
set.seed(7)

cv.youth2 <- cv.tree(tree_youth2, FUN = prune.misclass)
names(cv.youth2)
cv.youth2
```


```{r}
plot(cv.youth2$size, cv.youth2$dev, type = "b",
     xlab = "Tree Size (Number of Terminal Nodes)",
     ylab = "CV Classification Error Rate",
     main = "CV Error vs. Tree Size",
     pch = 19, col = "blue")
```


```{r}
optimal_size_CV2 <- cv.youth2$size[which.min(cv.youth2$dev)]
optimal_size_CV2
```


```{r}
pruned_tree2 <- prune.misclass(tree_youth2, best = 3)
pruned_tree2

plot(pruned_tree2, main = "Pruned tree")
text(pruned_tree2, pretty = 0)
```


```{r}
testing_data <- as.data.frame(testing_data)
prune_pred_youth2 <- predict(pruned_tree2, testing_data, type = "class")

confusion_matrix_pru2 <- table(Predicted = prune_pred_youth2, Actual = testing_data$TOBFLAG)
confusion_matrix_pru2

accuracy_pru2 <- mean(prune_pred_youth2 == testing_data$TOBFLAG)
#(2002+89)/(2002+89+230+154)
test_error_rate_pru2 <- 1 - accuracy_pru2
#(230+154)/2475

cat('Accuracy:', mean(prune_pred_youth2 == testing_data$TOBFLAG), "\n")
cat('Test Error Rate:', round(test_error_rate_pru2, 4), "\n")
```


## 3.2 Binary Classification --> Bagging --> with TOBFLAG --> any tobacco ever used (0 = never, 1 = ever)

```{r}
library(randomForest)

training_data_clean <- na.omit(training_data) 
bag_youth2 = randomForest(TOBFLAG ~ ., data = training_data_clean, mtry = floor(sqrt(ncol(training_data_clean))), importance = TRUE)
bag_youth2
```


```{r}
pred_bag_youth2 = predict(bag_youth2, newdata = testing_data, type = 'class')

confusion_matrix_bag2 <- table(Predicted = pred_bag_youth2, Actual = testing_data$TOBFLAG)
confusion_matrix_bag2

accuracy_bag2 <- mean(pred_bag_youth2 == testing_data$TOBFLAG)
#(2224+16)/(2224+16+8+227)
test_error_rate_bag2 <- 1 - accuracy_bag2
#(8+227)/2475

cat('Accuracy:', mean(pred_bag_youth2 == testing_data$TOBFLAG), "\n")
cat('Test Error Rate:', round(test_error_rate_bag2, 4), "\n")
```


```{r}
top_10_bag2_TOBFLAG = head(importance(bag_youth2),10)
top_10_bag2_TOBFLAG
```


```{r}
varImpPlot(bag_youth2, n.var = 10, sort = TRUE, main = 'The Most Important 10 Variables_TOBFLAG_Bagging')
```


## 3.3 Binary Classification --> Random Forest --> with TOBFLAG --> any tobacco ever used (0 = never, 1 = ever)

```{r}
set.seed(1)
rf_youth2 = randomForest(TOBFLAG ~ ., data = training_data_clean, mtry = sqrt(ncol(training_data_clean)), importance = TRUE)
rf_youth2
```


```{r}
yhat.rf <- predict(rf_youth2, newdata = testing_data, type = 'class')

confusion_matrix_rf2 <- table(Predicted = yhat.rf, Actual = testing_data$TOBFLAG)
confusion_matrix_rf2

accuracy_rf2 <- mean(yhat.rf == testing_data$TOBFLAG, na.rm = TRUE)
test_error_rate_rf2 <- 1 - accuracy_rf2

cat("Accuracy:", round(accuracy_rf2, 4), "\n")
cat("Test Error Rate:", round(test_error_rate_rf2, 4), "\n")
```


```{r}
top_10_rf2_TOBFLAG = head(importance(rf_youth2),10)
top_10_rf2_TOBFLAG
```


```{r}
varImpPlot(rf_youth2, n.var = 10, sort = TRUE, main = 'The Most Important 10 Variables_TOBFLAG_Random Forest')
```



## 4.1 Binary classification (e.g. has or has not used cigarettes) Tree with ALCFLAG --> alcohol ever used (0 = never, 1 = ever)

```{r}
youth_binary3 <- cleaned_youth_data[, c(demographic_cols, youth_experience_cols, "ALCFLAG")]
youth_binary3$ALCFLAG <- as.factor(youth_binary3$ALCFLAG)

set.seed(123)

training_set <- sample(1:nrow(youth_binary3), 0.7 * nrow(youth_binary3))
training_data <- youth_binary3[training_set, ]
testing_data <- youth_binary3[-training_set, ]

tree_youth3 <- tree(ALCFLAG ~ ., data = training_data)
summary(tree_youth3)
```


```{r}
tree_youth3
```



```{r}
plot(tree_youth3)
text(tree_youth3, pretty = 0)
```


```{r}
testing_data <- as.data.frame(testing_data)
test_pred <- predict(tree_youth3, testing_data, type = "class")

confusion_matrix_alcflag <- table(Predicted = test_pred, Actual = testing_data$ALCFLAG)
confusion_matrix_alcflag

accuracy_alcflag <- mean(test_pred == testing_data$ALCFLAG)
#(1768+180)/(1768+180+87+440)
test_error_rate_alcflag <- 1 - accuracy_alcflag
#(87+440)/2475

cat('Accuracy:', mean(test_pred == testing_data$ALCFLAG), "\n")
cat('Test Error Rate:', round(test_error_rate_alcflag, 4), "\n")
```


```{r}
set.seed(7)

cv.youth3 <- cv.tree(tree_youth3, FUN = prune.misclass)
names(cv.youth3)
cv.youth3
```


```{r}
plot(cv.youth3$size, cv.youth3$dev, type = "b",
     xlab = "Tree Size (Number of Terminal Nodes)",
     ylab = "CV Classification Error Rate",
     main = "CV Error vs. Tree Size",
     pch = 19, col = "blue")
```


```{r}
optimal_size_CV3 <- cv.youth3$size[which.min(cv.youth3$dev)]
optimal_size_CV3
```


```{r}
pruned_tree3 <- prune.misclass(tree_youth3, best = 5)
pruned_tree3 <- prune.misclass(tree_youth3, best = 5)
pruned_tree3

plot(pruned_tree3, main = "Pruned tree")
text(pruned_tree3, pretty = 0)
```


```{r}
testing_data <- as.data.frame(testing_data)
prune_pred_youth3 = predict(pruned_tree3, testing_data, type = 'class')

confusion_matrix_pru3 <- table(Predicted = prune_pred_youth3, Actual = testing_data$ALCFLAG)
confusion_matrix_pru3

accuracy_pru3 <- mean(prune_pred_youth3 == testing_data$ALCFLAG)
#(1738+202)/(1738+202+117+418)
test_error_rate_pru3 <- 1 - accuracy_pru3
#(117+418)/2475

cat('Accuracy:', mean(prune_pred_youth3 == testing_data$ALCFLAG), "\n")
cat('Test Error Rate:', round(test_error_rate_pru3, 4), "\n")
```


## 4.2 Binary Classification --> Bagging --> with ALCFLAG --> alcohol ever used (0 = never, 1 = ever)

```{r}
library(randomForest)

training_data_clean = na.omit(training_data) 
bag_youth3 = randomForest(ALCFLAG ~ ., data = training_data_clean, mtry = floor(sqrt(ncol(training_data_clean))), importance = TRUE)
bag_youth3
```


```{r}
pred_bag_youth3 = predict(bag_youth3, newdata = testing_data, type = 'class')

confusion_matrix_bag3 <- table(Predicted = pred_bag_youth3, Actual = testing_data$ALCFLAG)
confusion_matrix_bag3

accuracy_bag3 <- mean(pred_bag_youth3 == testing_data$ALCFLAG)
#(2224+16)/(2224+16+8+227)
test_error_rate_bag3 <- 1 - accuracy_bag3
#(8+227)/2475

cat('Accuracy:', mean(pred_bag_youth3 == testing_data$ALCFLAG), "\n")
cat('Test Error Rate:', round(test_error_rate_bag3, 4), "\n")
```


```{r}
top_10_bag3_ALCFLAG = head(importance(bag_youth3),10)
top_10_bag3_ALCFLAG
```


```{r}
varImpPlot(bag_youth3, n.var = 10, sort = TRUE, main = 'The Most Important 10 Variables_ALCFLAG_Bagging')
```



## 4.3 Binary Classification --> Random Forest --> with ALCFLAG --> alcohol ever used (0 = never, 1 = ever)

```{r}
set.seed(1)
rf_youth3 = randomForest(ALCFLAG ~ ., data = training_data_clean, mtry = sqrt(ncol(training_data_clean)), importance = TRUE)
rf_youth3
```


```{r}
yhat.rf <- predict(rf_youth3, newdata = testing_data, type = 'class')

confusion_matrix_rf3 <- table(Predicted = yhat.rf, Actual = testing_data$ALCFLAG)
confusion_matrix_rf3

accuracy_rf3 <- mean(yhat.rf == testing_data$ALCFLAG, na.rm = TRUE)
test_error_rate_rf3 <- 1 - accuracy_rf3

cat("Accuracy:", round(accuracy_rf3, 4), "\n")
cat("Test Error Rate:", round(test_error_rate_rf3, 4), "\n")
```


```{r}
top_10_rf3_ALCFLAG = head(importance(rf_youth3),10)
top_10_rf3_ALCFLAG
```


```{r}
varImpPlot(rf_youth3, n.var = 10, sort = TRUE, main = 'The Most Important 10 Variables_ALCFLAG_Random Forest')
```



## 5.1 Compare Binary Classification Methods ---> Tree with MRJFLAG --> Marijuana ever used (0 = never, 1 = ever)

```{r}
library(ggplot2)

model_names <- c("Decision Tree", "Pruned Tree", "Bagging", "Random Forest")
accuracy_values <- c(accuracy_dt, accuracy_pru2, accuracy_bag2, accuracy_rf2)
error_rate_values <- c(test_error_rate_dt, test_error_rate_pru2, test_error_rate_bag2, test_error_rate_rf2)

comparison_df <- data.frame(
  Model = rep(model_names, times = 2),
  Metric = rep(c("Accuracy", "Test Error Rate"), each = length(model_names)),
  Value = c(accuracy_values, error_rate_values)
)

ggplot(comparison_df, aes(x = Model, y = Value, fill = Metric)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_text(aes(label = paste0(round(Value * 100, 1), "%")),  
            position = position_dodge(width = 0.9), 
            vjust = -0.3, size = 3.5) +
  labs(title = "Accuracy vs Test Error Rate with Marijuana",
       x = "Model", y = "Percentage") +
  theme_minimal() +
  ylim(0, 1)
```


## 5.2 Compare Binary Classification Methods ---> Tree with TOBFLAG --> any Tobacco ever used (0 = never, 1 = ever) 

```{r}
library(ggplot2)

model_names <- c("Decision Tree", "Pruned Tree", "Bagging", "Random Forest")
accuracy_values <- c(accuracy_tobflag, accuracy_pru2, accuracy_bag2, accuracy_rf2)
error_rate_values <- c(test_error_rate_tobflag, test_error_rate_pru2, test_error_rate_bag2, test_error_rate_rf2)

comparison_df <- data.frame(
  Model = rep(model_names, times = 2),
  Metric = rep(c("Accuracy", "Test Error Rate"), each = length(model_names)),
  Value = c(accuracy_values, error_rate_values)
)

# Bar plot with percentage labels
ggplot(comparison_df, aes(x = Model, y = Value, fill = Metric)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_text(aes(label = paste0(round(Value * 100, 1), "%")),
            position = position_dodge(width = 0.9), 
            vjust = -0.3, size = 3.5) +
  labs(title = "Accuracy vs Test Error Rate with Tobacco",
       x = "Model", y = "Percentage") +
  theme_minimal() +
  ylim(0, 1)
```


## 5.3 Compare Binary Classification Methods ---> Tree with ALCFLAG --> Alcohol ever used (0 = never, 1 = ever)

```{r}
library(ggplot2)

model_names <- c("Decision Tree", "Pruned Tree", "Bagging", "Random Forest")
accuracy_values <- c(accuracy_alcflag, accuracy_pru3, accuracy_bag3, accuracy_rf3)
error_rate_values <- c(test_error_rate_alcflag, test_error_rate_pru3, test_error_rate_bag3, test_error_rate_rf3)

comparison_df <- data.frame(
  Model = rep(model_names, times = 2),
  Metric = rep(c("Accuracy", "Test Error Rate"), each = length(model_names)),
  Value = c(accuracy_values, error_rate_values)
)

ggplot(comparison_df, aes(x = Model, y = Value, fill = Metric)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  geom_text(aes(label = paste0(round(Value * 100, 1), "%")),
            position = position_dodge(width = 0.9), 
            vjust = -0.4, size = 3.5) +
  labs(title = "Accuracy vs Test Error Rate with Alcohol",
       x = "Methods", y = "Percentage") +
  theme_minimal() +
  ylim(0, 1)
```



## 5.4 Binary Model Comparison: Accuracy vs Test Error Rate for Each Model

```{r}
library(ggplot2)

model_names <- c("Decision Tree", "Pruned Tree", "Bagging", "Random Forest")

accuracy_marijuana <- c(accuracy_dt, accuracy_pru2, accuracy_bag2, accuracy_rf2)
error_marijuana    <- c(test_error_rate_dt, test_error_rate_pru2, test_error_rate_bag2, test_error_rate_rf2)

accuracy_tobacco <- c(accuracy_tobflag, accuracy_pru2, accuracy_bag2, accuracy_rf2)
error_tobacco    <- c(test_error_rate_tobflag, test_error_rate_pru2, test_error_rate_bag2, test_error_rate_rf2)

accuracy_alcohol <- c(accuracy_alcflag, accuracy_pru3, accuracy_bag3, accuracy_rf3)
error_alcohol    <- c(test_error_rate_alcflag, test_error_rate_pru3, test_error_rate_bag3, test_error_rate_rf3)

substances <- c("Marijuana", "Tobacco", "Alcohol")
x_labels <- paste(rep(substances, each = length(model_names)),
                  rep(model_names, times = length(substances)),
                  sep = " - ")

comparison_df <- data.frame(
  Method = rep(x_labels, times = 2),
  Metric = rep(c("Accuracy", "Test Error Rate"), each = length(x_labels)),
  Value = c(accuracy_marijuana, accuracy_tobacco, accuracy_alcohol,
            error_marijuana, error_tobacco, error_alcohol)
)

custom_palette <- c("Accuracy" = "#0072B2", "Test Error Rate" = "#56B4E9")

# Plot
ggplot(comparison_df, aes(x = Method, y = Value, fill = Metric)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  geom_text(aes(label = paste0(round(Value * 100, 1), "%")),
            position = position_dodge(width = 0.9),
            vjust = -0.25, size = 3) +
  scale_fill_manual(values = custom_palette) +
  labs(title = "Binary Model Comparison: Accuracy vs Test Error Rate for Each Model",
       x = "All Binary Models", y = "Percentage") +
  theme_minimal() +
  ylim(0, 1) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


## 6. The Subset of Best 22 features from the Binary Models

```{r}
url <- "https://raw.githubusercontent.com/mendible/5322/main/Homework%201/youth_data.Rdata"
download.file(url, destfile = "youth_data.Rdata", mode = "wb")

loaded_dataset <- load("youth_data.Rdata")
youth_data_df <- get(loaded_dataset[1])

cleaned_youth_data <- na.omit(youth_data_df)
youth <- cleaned_youth_data

if (!"PRADLY2" %in% names(youth)) {
  youth$PRADLY2 <- NA
}

important_vars <- c(
  "YFLMJMO", "FRDMJMON", "YFLTMRJ2", "EDUSCHGRD2", "STNDSMJ",
  "FRDMEVR2", "YOSTOLE2", "NEWRACE2", "HEALTH2", "EDUSKPCOM",
  "PRMJEVR2", "STNDALC", "INCOME", "FRDPCIG2", "FRDADLY2",
  "POVERTY3", "PRMJMO", "PDEN10", "YOSELL2", "COUTYP4",
  "PRALDLY2", "PRADLY2"
)

target_vars <- c("MRJFLAG", "TOBFLAG", "ALCFLAG")

all_vars <- unique(c(important_vars, target_vars))
existing_vars <- all_vars[all_vars %in% names(youth)]

youth_fltrd <- youth[, existing_vars]
#youth_fltrd
```



## 7.1 Multi-class Classification ---> (differentiate between seldom, sometimes, and frequent marijuana use) ---> MRJYDAYS ---> Number of days of marijuana in past month (1-4 categories, 5 = none)

```{r}
youth_multi <- df[,c(demographic_cols, youth_experience_cols,'CIGMDAYS')]
youth_multi <- na.omit(youth_multi)
youth_multi$CIGMDAYS <- as.factor(youth_multi$CIGMDAYS)
#youth_multi
```


```{r}
train_indices <- sample(1:nrow(youth_multi), 0.7*nrow(youth_multi))
train_multi <- youth_multi[train_indices,]
test_multi <- youth_multi[-train_indices,]
```


```{r}
tree_multi <- tree(CIGMDAYS ~., data = train_multi)
tree_multi

plot(tree_multi,type = 'uniform')
text(tree_multi, pretty=0, cex  = 0.8)
```


```{r}
pred_multi <- predict(tree_multi, test_multi, type = 'class')

confusion_matrix_dt <- table(Predicted = pred_multi, Actual = test_multi$CIGMDAYS)
confusion_matrix_dt

accuracy_dt <- mean(pred_multi == test_multi$CIGMDAYS)
test_error_rate_dt <- 1 - accuracy_dt

cat('Accuracy:', round(accuracy_dt, 4), "\n")
cat('Test Error Rate:', round(test_error_rate_dt, 4), "\n")
```


```{r}
cv.multi = cv.tree(tree_multi, FUN = prune.misclass)
names(cv.multi)
cv.multi
```

```{r}
par(mfrow = c(1, 2))
plot(cv.multi$size, cv.multi$dev, type = "b")
plot(cv.multi$k, cv.multi$dev, type = "b")
```


```{r}
prune.multi = prune.misclass(tree_multi, best = 3)
prune.multi

plot(prune.multi, type ='uniform')
text(prune.multi, pretty = 0, cex = 0.8)
```


```{r}
prune_pred_multi <- predict(prune.multi, test_multi, type = 'class')

confusion_matrix_pru <- table(Predicted = prune_pred_multi, Actual = test_multi$CIGMDAYS)
confusion_matrix_pru

accuracy_pru <- mean(prune_pred_multi == test_multi$CIGMDAYS)
cat('Accuracy:', round(accuracy_pru, 4), "\n")

test_error_rate_pru <- 1 - accuracy_pru
cat('Test Error Rate:', round(test_error_rate_pru, 4), "\n")
```


## 7.2 Multi-class Classification ---> Bagging ---> CIGMDAYS

```{r}
library(randomForest)

train_multi_clean = na.omit(train_multi) 
bag_multi = randomForest(CIGMDAYS ~ ., data = train_multi_clean, mtry = (sqrt(ncol(train_multi_clean))), importance = TRUE)
bag_multi
```



```{r}
pred_bag_multi <- predict(bag_multi, newdata = test_multi, type = 'class')

confusion_matrix_bag <- table(Predicted = pred_bag_multi, Actual = test_multi$CIGMDAYS)
confusion_matrix_bag

accuracy_bag <- mean(pred_bag_multi == test_multi$CIGMDAYS, na.rm = TRUE)
cat('Accuracy:', round(accuracy_bag, 4), "\n")

test_error_rate_bag <- 1 - accuracy_bag
cat('Test Error Rate:', round(test_error_rate_bag, 4), "\n")
```


```{r}
top_10_bag_CIGMDAYS = head(importance(bag_multi),10)
top_10_bag_CIGMDAYS
```


```{r}
varImpPlot(bag_multi, n.var = 10, sort = TRUE, main = 'The Most Important 10 variables_CIGMDAYS_Bagging_Multi class Classification')
```



## 7.3 Multi-class Classification ---> RandomForest ---> CIGMDAYS

```{r}
set.seed(1)
rf_multi = randomForest(CIGMDAYS ~ ., data = train_multi_clean, mtry = sqrt(ncol(train_multi_clean)), importance = TRUE)
rf_multi
```



```{r}
yhat.rf <- predict(rf_multi, newdata = test_multi, type = 'class')

confusion_matrix_rf <- table(Predicted = yhat.rf, Actual = test_multi$CIGMDAYS)
confusion_matrix_rf

accuracy_rf <- mean(yhat.rf == test_multi$CIGMDAYS, na.rm = TRUE)
cat('Accuracy:', round(accuracy_rf, 4), "\n")

test_error_rate_rf <- 1 - accuracy_rf
cat('Test Error Rate:', round(test_error_rate_rf, 4), "\n")
```

```{r}
top_10_rf_CIGMDAYS = head(importance(rf_multi),10)
top_10_rf_CIGMDAYS
```


```{r}
varImpPlot(rf_multi, n.var = 10, sort = TRUE, main = 'Important 10 variables_CIGMDAYS_RandomForest_Multiclass Classification')
```


## 7.4 Compare Multi class Classification Models

```{r}
library(ggplot2)

model_names <- c("Decision Tree", "Pruned Tree", "Bagging", "Random Forest")

accuracy_values <- c(accuracy_dt, accuracy_pru, accuracy_bag, accuracy_rf)
error_rate_values <- c(test_error_rate_dt, test_error_rate_pru, test_error_rate_bag, test_error_rate_rf)

comparison_df <- data.frame(
  Model = rep(model_names, times = 2),
  Metric = rep(c("Accuracy", "Test Error Rate"), each = length(model_names)),
  Value = c(accuracy_values, error_rate_values)
)

comparison_df$Label <- paste0(round(comparison_df$Value * 100, 1), "%")

ggplot(comparison_df, aes(x = Model, y = Value, fill = Metric)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  geom_text(aes(label = Label),
            position = position_dodge(width = 0.9),
            vjust = -0.4, size = 3.5) +
  scale_fill_manual(values = c("Accuracy" = "#1f78b4", "Test Error Rate" = "#a6cee3")) +
  labs(title = "Multi class Classification Models Comparison",
       y = "Value", x = "Model") +
  theme_minimal()
```

## 8.1 Regression ---> Decision Tree ---> IRCIGAGE ---> Cigarette age of first use (1-55), 991=never used

```{r}
library(dplyr)

youth_reg <- df[, c(demographic_cols, youth_experience_cols, 'IRCIGAGE')] %>%
  filter(!is.na(IRCIGAGE) & IRCIGAGE != 991) %>%
  na.omit()
#youth_reg
```



```{r}
train_indices <- sample(1:nrow(youth_reg), 0.7*nrow(youth_reg))
train_reg <- youth_reg[train_indices,]
test_reg <- youth_reg[-train_indices,]
```



```{r}
library(tree)

tree_reg <- tree(IRCIGAGE ~., data = train_reg)
tree_reg

plot(tree_reg,type = 'uniform')
text(tree_reg, pretty=0, cex = 0.8)
```

```{r}
pred_reg <- predict(tree_reg, test_reg)

mse_tree <- mean((pred_reg - test_reg$IRCIGAGE)^2)
cat("Mean Squared Error (MSE):", round(mse_tree, 4), "\n")

rmse_tree <- sqrt(mse_tree)
cat("Root Mean Squared Error (RMSE):", round(rmse_tree, 4), "\n")
```


```{r}
cv.reg = cv.tree(tree_reg, FUN = prune.tree)
names(cv.reg)
cv.reg
```


```{r}
par(mfrow = c(1, 2))
plot(cv.reg$size, cv.reg$dev, type = "b")
plot(cv.reg$k, cv.reg$dev, type = "b")
```


```{r}
prune.reg_tree = prune.tree(tree_reg, best = 4)
prune.reg_tree

plot(prune.reg_tree, type ='uniform')
text(prune.reg_tree, pretty = 0)
```


```{r}
prune_pred_reg <- predict(prune.reg_tree, test_reg)

mse_prune <- mean((prune_pred_reg - test_reg$IRCIGAGE)^2)
cat("Mean Squared Error (MSE):", round(mse_prune, 4), "\n")

rmse_prune <- sqrt(mse_prune)
cat("Root Mean Squared Error (RMSE):", round(rmse_prune, 4), "\n")
```


## 8.2 Regression ---> Bagging ---> IRCIGAGE ---> Cigarette age of first use (1-55), 991=never used

```{r}
library(randomForest)

train_reg_clean = na.omit(train_reg) 
bag_reg = randomForest(IRCIGAGE ~ ., data = train_reg_clean, mtry = floor(ncol(train_reg)/3), importance = TRUE)
bag_reg
```


```{r}
pred_bag_reg <- predict(bag_reg, newdata = test_reg)

mse_bag <- mean((pred_bag_reg - test_reg$IRCIGAGE)^2, na.rm = TRUE)
cat("Mean Squared Error (MSE):", round(mse_bag, 4), "\n")

rmse_bag <- sqrt(mse_bag)
cat("Root Mean Squared Error (RMSE):", round(rmse_bag, 4), "\n")
```


```{r}

top_10_bag_IRCIGAGE = head(importance(bag_reg),10)
top_10_bag_IRCIGAGE
```


```{r}
varImpPlot(bag_reg, n.var = 10, sort = TRUE, main = 'Important 10 variables_IRCIGAGE_Bagging_Regression')
```


## 8.3 Regression ---> RandomForest ---> IRCIGAGE ---> Cigarette age of first use (1-55), 991=never used

```{r}
set.seed(1)
rf_reg = randomForest(IRCIGAGE  ~ ., data = train_reg_clean, mtry = floor(ncol(train_reg)/3), importance = TRUE)
rf_reg
```


```{r}
yhat.rf <- predict(rf_reg, newdata = test_reg)

mse_rf <- mean((yhat.rf - test_reg$IRCIGAGE)^2, na.rm = TRUE)
cat("Mean Squared Error (MSE):", round(mse_rf, 4), "\n")

rmse_rf <- sqrt(mse_rf)
cat("Root Mean Squared Error (RMSE):", round(rmse_rf, 4), "\n")
```


```{r}
top_10_bag_IRCIGAGE = head(importance(rf_reg),10)
top_10_bag_IRCIGAGE
```


```{r}
varImpPlot(rf_reg, n.var = 10, sort = TRUE, main = 'Important 10 variables_IRCIGAGE_RandomForest_Regression')
```


## 8.4 Compare Regression Methods ---> IRCIGAGE --->  Cigarette age of first use (1-55), 991=never used

```{r}
library(ggplot2)

model_names <- c("Decision Tree", "Pruned Tree", "Bagging", "Random Forest")

mse_values <- c(mse_tree, mse_prune, mse_bag, mse_rf)
rmse_values <- c(rmse_tree, rmse_prune, rmse_bag, rmse_rf)

error_df <- data.frame(
  Model = rep(model_names, times = 2),
  Metric = factor(rep(c("MSE", "RMSE"), each = length(model_names)), 
                  levels = c("MSE", "RMSE")),
  Value = c(mse_values, rmse_values)
)

ggplot(error_df, aes(x = Model, y = Value, fill = Metric)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  geom_text(aes(label = round(Value, 2)), 
            position = position_dodge(width = 0.9), 
            vjust = -0.3, size = 3.5) +
  labs(title = "Comparison of Test Error Metrics for Regression IRCIGAGE",
       x = "Model",
       y = "Error Value") +
  scale_fill_manual(values = c("MSE" = "#1f77b4", "RMSE" = "#6baed6")) +  # Custom blues
  theme_minimal()
```

